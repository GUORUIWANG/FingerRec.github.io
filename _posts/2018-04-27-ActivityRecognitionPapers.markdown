---
title:  "Activity_Recognition_Papers"   
date:   2018-04-11 10:50:23  
categories: [ActivityRecognition]  
tags: [ActivityRecognition]  

---

<script type="text/javascript"
   src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
<script type="text/x-mathjax-config"> MathJax.Hub.Config({ TeX: { equationNumbers: { autoNumber: "all" } } }); </script>


---

## Record

1.Simonyan, K., & Zisserman, A. (2014). Two-stream convolutional networks for action recognition in videos. In Advances in neural information processing systems (pp. 568-576).[[paper](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Feichtenhofer_Convolutional_Two-Stream_Network_CVPR_2016_paper.pdf)]

2.Feichtenhofer, C., Pinz, A., & Zisserman, A. P. (2016). Convolutional two-stream network fusion for video action recognition.[[paper](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Feichtenhofer_Convolutional_Two-Stream_Network_CVPR_2016_paper.pdf)][[github](https://github.com/feichtenhofer/twostreamfusion)]

3.Varol, G., Laptev, I., & Schmid, C. (2017). Long-term temporal convolutions for action recognition. IEEE transactions on pattern analysis and machine intelligence.[[paper](https://arxiv.org/pdf/1604.04494)][[github](https://github.com/gulvarol/ltc)]

4.Zhu, J., Zou, W., & Zhu, Z. (2017). End-to-end Video-Level Representation Learning for Action Recognition. arXiv preprint arXiv:1711.04161.[[paper](https://arxiv.org/pdf/1711.04161)][[github](https://github.com/zhujiagang/DTPP)]

5.Sevilla-Lara, L., Liao, Y., Guney, F., Jampani, V., Geiger, A., & Black, M. J. (2017). On the Integration of Optical Flow and Action Recognition. arXiv preprint arXiv:1712.08416.[[paper](https://arxiv.org/pdf/1712.08416)]

6.Wang, L., Xiong, Y., Wang, Z., Qiao, Y., Lin, D., Tang, X., & Van Gool, L. (2016, October). Temporal segment networks: Towards good practices for deep action recognition. In European Conference on Computer Vision (pp. 20-36). Springer, Cham.[[paper](https://arxiv.org/pdf/1608.00859)][[github](https://github.com/yjxiong/temporal-segment-networks)]

7.Carreira, J., & Zisserman, A. (2017, July). Quo vadis, action recognition? a new model and the kinetics dataset. In 2017 IEEE Conference on Computer Vision and Pattern Recognition (CVPR) (pp. 4724-4733). IEEE.[[paper](http://openaccess.thecvf.com/content_cvpr_2017/papers/Carreira_Quo_Vadis_Action_CVPR_2017_paper.pdf)]

8.Sun, S., Kuang, Z., Ouyang, W., Sheng, L., & Zhang, W. (2017). Optical Flow Guided Feature: A Fast and Robust Motion Representation for Video Action Recognition. arXiv preprint arXiv:1711.11152.[[paper](https://arxiv.org/pdf/1711.11152)]

9.Wang, H., & Schmid, C. (2013, December). Action recognition with improved trajectories. In Computer Vision (ICCV), 2013 IEEE International Conference on (pp. 3551-3558). IEEE.[[paper](https://www.cv-foundation.org/openaccess/content_iccv_2013/papers/Wang_Action_Recognition_with_2013_ICCV_paper.pdf)]

10.Sevilla-Lara, Laura, et al. "On the Integration of Optical Flow and Action Recognition." arXiv preprint arXiv:1712.08416 (2017).[[paper](https://arxiv.org/pdf/1712.08416.pdf)][[Reading notes]()]

## Extra


[TheReference](https://arxiv.org/pdf/1711.04161)

![acc_rank](http://owvctf4l4.bkt.clouddn.com/acc_rank.png)
